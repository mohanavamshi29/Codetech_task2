pip install numpy pandas matplotlib statsmodels tensorflow scikit-learn yfinance
import yfinance as yf

# Fetch historical data for a specific stock, e.g., 'AAPL'
ticker = 'AAPL'
data = yf.download(ticker, start='2020-01-01', end='2023-01-01')

# Display the first few rows of the data
print(data.head())
import pandas as pd

# Use closing prices
data = data[['Close']]

# Check for missing values
print(data.isna().sum())

# Fill missing values if any
data = data.fillna(method='ffill')
from statsmodels.tsa.arima.model import ARIMA
import matplotlib.pyplot as plt

# Split data into training and testing sets
train_size = int(len(data) * 0.8)
train, test = data[:train_size], data[train_size:]

# Fit ARIMA model
model = ARIMA(train, order=(5, 1, 0))  # Order can be tuned
model_fit = model.fit()

# Forecast
forecast = model_fit.forecast(steps=len(test))

# Plot results
plt.figure(figsize=(12, 6))
plt.plot(data.index[:train_size], train, label='Training Data')
plt.plot(data.index[train_size:], test, label='Actual Data')
plt.plot(data.index[train_size:], forecast, label='Forecast')
plt.legend()
plt.show()
import numpy as np
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense

# Prepare data for LSTM
scaler = MinMaxScaler(feature_range=(0, 1))
scaled_data = scaler.fit_transform(data)

def create_dataset(dataset, look_back=1):
    X, Y = [], []
    for i in range(len(dataset) - look_back - 1):
        a = dataset[i:(i + look_back), 0]
        X.append(a)
        Y.append(dataset[i + look_back, 0])
    return np.array(X), np.array(Y)

look_back = 10
X, y = create_dataset(scaled_data, look_back)

# Reshape for LSTM
X = np.reshape(X, (X.shape[0], X.shape[1], 1))

# Split into training and testing sets
X_train, X_test = X[:train_size-look_back], X[train_size-look_back:]
y_train, y_test = y[:train_size-look_back], y[train_size-look_back:]

# Build and train LSTM model
model = Sequential()
model.add(LSTM(50, input_shape=(look_back, 1), return_sequences=True))
model.add(LSTM(50))
model.add(Dense(1))

model.compile(optimizer='adam', loss='mean_squared_error')
model.fit(X_train, y_train, epochs=10, batch_size=32, verbose=1)

# Make predictions
predictions = model.predict(X_test)
predictions = scaler.inverse_transform(predictions)

# Plot results
plt.figure(figsize=(12, 6))
plt.plot(data.index[look_back:train_size], test[look_back:], label='Actual Data')
plt.plot(data.index[train_size:], predictions, label='LSTM Forecast')
plt.legend()
plt.show()
import numpy as np
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense

# Prepare data for LSTM
scaler = MinMaxScaler(feature_range=(0, 1))
scaled_data = scaler.fit_transform(data)

def create_dataset(dataset, look_back=1):
    X, Y = [], []
    for i in range(len(dataset) - look_back - 1):
        a = dataset[i:(i + look_back), 0]
        X.append(a)
        Y.append(dataset[i + look_back, 0])
    return np.array(X), np.array(Y)

look_back = 10
X, y = create_dataset(scaled_data, look_back)

# Reshape for LSTM
X = np.reshape(X, (X.shape[0], X.shape[1], 1))

# Split into training and testing sets
X_train, X_test = X[:train_size-look_back], X[train_size-look_back:]
y_train, y_test = y[:train_size-look_back], y[train_size-look_back:]

# Build and train LSTM model
model = Sequential()
model.add(LSTM(50, input_shape=(look_back, 1), return_sequences=True))
model.add(LSTM(50))
model.add(Dense(1))

model.compile(optimizer='adam', loss='mean_squared_error')
model.fit(X_train, y_train, epochs=10, batch_size=32, verbose=1)

# Make predictions
predictions = model.predict(X_test)
predictions = scaler.inverse_transform(predictions)

# Plot results
plt.figure(figsize=(12, 6))
plt.plot(data.index[look_back:train_size], test[look_back:], label='Actual Data')
plt.plot(data.index[train_size:], predictions, label='LSTM Forecast')
plt.legend()
plt.show()
